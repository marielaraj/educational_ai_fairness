# Tutorial educativo abierto para la evaluación de equidad en los modelos de clasificación de Inteligencia Artificial (IA)

## ¡Hola!

Gracias por visitar el repositorio del proyecto "Tutorial  educativo para la evaluación de equidad en los modelos de clasificación de IA".

### Visión del proyecto:
Trabajamos para la generación de materiales educativos, especificamente, materiales para dictar talleres que se centren en comprender cómo estudiar el sesgo de los modelos de aprendizaje automático. Buscamos que sean materiales que educadoras y profesionales de IA puedan usar y adapta para sus cursos de IA.


## ¿Que estamos haciendo?

### El problema

Si bien los sistemas de IA brindan múltiples beneficios, es necesaria la conciencia sobre los sesgos y las consecuencias que pueden generar o propagar en la sociedad. En el contexto del aprendizaje supervisado combinado con datos de personas, las evaluaciones de modelos generalmente se enfocan en comparar etiquetas pronosticadas y anotadas sin tener en cuenta las **diferencias que los modelos producen (generalmente) sobre grupos históricamente desfavorecidos de la sociedad**. Además, **más de 20 definiciones de equidad** se proponen en la bibliografía, y las combinaciones de las mismas no son necesariamente factibles o no tienen sentido matemático. Por lo tanto, **analizar la definición adecuada que se utilizará en un problema específico no es trivial**.

### La solución

Una forma de contribuir al desarrollo de modelos más justos es **generar materiales educativos abiertos** que expliquen y difundan la importancia de evaluar la equidad en los modelos y cuáles son las métricas convenientes para cada objetivo asi también como entender qué limitaciones tiene cada elección antes de usarlos en la sociedad.


## ¿Quienes somos?


## ¿Qué necesitamos?


## Involucrarse

Si está interesado en participar en el proyecto, puede consultar nuestras [directrices para colaboradores](CONTRIBUTING.md).

## Cronología?


## Contáctenos



## Saber más



## Gracias


## Glosario


## What are we doing?

### The problem

Although AI systems provide multiple benefits, awareness about the biases and consequences they may generate or spread in society is necessary. In the context of supervised learning combined with people data, model evaluations usually focus on comparing predicted and annotated labels without accountting the **differences that the models produce in (usually) historically disadvantaged groups of society**. Moreover, **more than 20 definitions of fairness** are proposed in the bibliography, and satisfying combinations of them are not necessarily possible or do not have mathematical sense. So, although researchers and deployers may consider *fairness*, **analyzing the appropriate definition to be used in a specific problem is not trivial**.

### The solution

One way to contribute to the development of fairer models is to **generate educational open-source materials** that explain and spread the importance of evaluating the fairness in the models and which of the metrics are convenient for each objective and understand which limitations they have before using them in society.


## Who are we?


## What do we need?


## Get involved

If you are interested in getting involved in the project, you can check  out our [contributors' guidelines](CONTRIBUTING.md).

## Timeline?


## Contact us



## Find out more



## Thank you


## Glossary
