# Tutorial educativo abierto para la evaluación de equidad en los modelos de clasificación de Inteligencia Artificial (IA)

## ¡Bienvenida!¡Bienvenide!¡Bienvenido!

Gracias por visitar el repositorio del proyecto "Tutorial  educativo para la evaluación de equidad en los modelos de clasificación de IA".

Nuestra **visión**: Trabajamos para la generación de materiales de talleres abiertos que se centren en comprender cómo estudiar el sesgo de los modelos de aprendizaje automático para que los educadores y los profesionales de IA puedan usar y adaptar los ejemplos concretos y diversos propuestos en los materiales para sus cursos de IA.


## ¿Que estamos haciendo?

### El problema

Si bien los sistemas de IA brindan múltiples beneficios, es necesaria la conciencia sobre los sesgos y las consecuencias que pueden generar o propagar en la sociedad. En el contexto del aprendizaje supervisado combinado con datos de personas, las evaluaciones de modelos generalmente se enfocan en comparar etiquetas pronosticadas y anotadas sin tener en cuenta las **diferencias que los modelos producen en (generalmente) grupos históricamente desfavorecidos de la sociedad**. Además, **más de 20 definiciones de equidad** se proponen en la bibliografía, y las combinaciones satisfactorias de ellas no son necesariamente posibles o no tienen sentido matemático. Por lo tanto, aunque los investigadores y los implementadores pueden considerar la *equidad*, **analizar la definición adecuada que se utilizará en un problema específico no es trivial**.

### La solución

Una forma de contribuir al desarrollo de modelos más justos es **generar materiales educativos de código abierto** que expliquen y difundan la importancia de evaluar la equidad en los modelos y cuáles de las métricas son convenientes para cada objetivo y entender qué limitaciones tienen. tienen antes de usarlos en la sociedad.


## ¿Quienes somos?


## ¿Qué necesitamos?


## Involucrarse

Si está interesado en participar en el proyecto, puede consultar nuestras [directrices para colaboradores](CONTRIBUTING.md).

## Cronología?


## Contáctenos



## Saber más



## Gracias


## Glosario


## What are we doing?

### The problem

Although AI systems provide multiple benefits, awareness about the biases and consequences they may generate or spread in society is necessary. In the context of supervised learning combined with people data, model evaluations usually focus on comparing predicted and annotated labels without accountting the **differences that the models produce in (usually) historically disadvantaged groups of society**. Moreover, **more than 20 definitions of fairness** are proposed in the bibliography, and satisfying combinations of them are not necessarily possible or do not have mathematical sense. So, although researchers and deployers may consider *fairness*, **analyzing the appropriate definition to be used in a specific problem is not trivial**.

### The solution

One way to contribute to the development of fairer models is to **generate educational open-source materials** that explain and spread the importance of evaluating the fairness in the models and which of the metrics are convenient for each objective and understand which limitations they have before using them in society.


## Who are we?


## What do we need?


## Get involved

If you are interested in getting involved in the project, you can check  out our [contributors' guidelines](CONTRIBUTING.md).

## Timeline?


## Contact us



## Find out more



## Thank you


## Glossary
