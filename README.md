# Open educational hands-on tutorial for evaluating fairness in AI classification models 



## Welcome!

Thank you for visiting the pen educational hands-on tutorial for evaluating fairness in AI classification models  project repository.

## What are we doing?

### The problem

Although AI systems provide multiple benefits, awareness about the biases and consequences they may generate or spread in society is necessary. In the context of supervised learning combined with people data, model evaluations usually focus on comparing predicted and annotated labels without accountting the **differences that the models produce in (usually) historically disadvantaged groups of society**. Moreover, **more than 20 definitions of fairness** are proposed in the bibliography, and satisfying combinations of them are not necessarily possible or do not have mathematical sense. So, although researchers and deployers may consider *fairness*, **analyzing the appropriate definition to be used in a specific problem is not trivial**.

### The solution

One way to contribute to the development of fairer models is to **generate educational open-source materials** that explain and spread the importance of evaluating the fairness in the models and which of the metrics are convenient for each objective and understand which limitations they have before using them in society.


## Who are we?


## What do we need?


## Get involved



## Contact us



## Find out more



## Thank you


## Glossary

